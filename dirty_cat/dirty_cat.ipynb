{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369c9d81-440c-4c00-9015-c70097c93fc2",
   "metadata": {},
   "source": [
    "# Calm Code Dirty Cat Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea2a85-bdbb-4e4a-933f-4c4adf12432d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7f115-6baa-43d8-a026-778ca3ca659a",
   "metadata": {},
   "source": [
    "For lesson notes, see the `README.md` file at `daltonturner/calm-code-practice/dirty_cat`. This notebook will focus on the coding portion of the Dirty Cat video series, which presents methods to deal with categorical variables using `scikit-learn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f607b17-9573-466d-a917-a4d1159e2bb7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a28ba8-4571-4e3a-9685-a034e0598401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These packages were installed using a virtual environment specifically set up for this video series\n",
    "# For additional information on the dependencies for this series, see https://calmcode.io/dirty-cat/introduction.html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dirty_cat import datasets\n",
    "\n",
    "employee_salaries = datasets.fetch_employee_salaries()\n",
    "data = employee_salaries['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4809392-6d7d-4123-a75a-e07e739e57f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Annual Salary</th>\n",
       "      <th>year_first_hired</th>\n",
       "      <th>assignment_category</th>\n",
       "      <th>employee_position_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69222.18</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Office Services Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97392.47</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Master Police Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104717.28</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Social Worker IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52734.57</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Resident Supervisor II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93396.00</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Planning Specialist III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Annual Salary  year_first_hired assignment_category  \\\n",
       "0               69222.18            1986.0    Fulltime-Regular   \n",
       "1               97392.47            1988.0    Fulltime-Regular   \n",
       "2              104717.28            1989.0    Fulltime-Regular   \n",
       "3               52734.57            2014.0    Fulltime-Regular   \n",
       "4               93396.00            2007.0    Fulltime-Regular   \n",
       "\n",
       "       employee_position_title  \n",
       "0  Office Services Coordinator  \n",
       "1        Master Police Officer  \n",
       "2             Social Worker IV  \n",
       "3       Resident Supervisor II  \n",
       "4      Planning Specialist III  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = 'Current Annual Salary'\n",
    "ml_df = data[[target_column, 'year_first_hired', 'assignment_category', 'employee_position_title']].dropna()\n",
    "y = ml_df[target_column].values.ravel()\n",
    "X = ml_df[['employee_position_title', 'year_first_hired', 'assignment_category']]\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e00073-e451-48e4-94ce-31f1ab158839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police Officer III                         883\n",
       "Firefighter/Rescuer III                    694\n",
       "Bus Operator                               638\n",
       "Manager III                                243\n",
       "Correctional Officer III (Corporal)        228\n",
       "                                          ... \n",
       "Medical Doctor IV - Physician                1\n",
       "Director Department of General Services      1\n",
       "Director Department of Finance               1\n",
       "Information Technology Project Manager       1\n",
       "Secretary to Appellate Judge                 1\n",
       "Name: employee_position_title, Length: 385, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts for each job title show us that certain titles appear much more frequently than others\n",
    "ml_df['employee_position_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00548872-2aa6-4744-a3e4-21c77ab9906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer can be used to extract words within text, and build features with them\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fitting the CountVectorizer to the employee_position_title column generates a sparse matrix\n",
    "# The sparse matrix tells us whether a given cell's contents contain an extracted word\n",
    "# The sparse matrix is better at using less memory\n",
    "cv = CountVectorizer().fit(ml_df['employee_position_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d167c86c-a7a8-49e8-aa43-008c34f08b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the .vocabulary_ method, we can see which words are being used to generate the sparse matrix\n",
    "# The number next to the word indicates which column the word is associated with, not the number of times the word appears\n",
    "cv.vocabulary_\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994140a8-fd5f-4b62-a9ca-947cb058dd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The analyzer and ngram_range CountVectorizer inputs allow you to generate additonal sub-words\n",
    "# This provides robustness against word mismatches\n",
    "cv = CountVectorizer(analyzer = 'char', ngram_range = (3,3)).fit(ml_df['employee_position_title'])\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5baf8336-febe-4def-932d-9d0db6aa0274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9228, 1264)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of the transformation shows us that the number of columns we now have is equal to the length of the\n",
    "# CountVectorizer's vocabulary\n",
    "cv.transform(ml_df['employee_position_title']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da7aa65-f92e-4db6-9254-e1af28fcc9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9228, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dirty_cat package allows us to generate similarity scores across a matrix, rather than encoding as 0 or 1 \n",
    "# for word or sub-word matches\n",
    "import dirty_cat\n",
    "\n",
    "# The SimilarityEncoder accepts optional inputs for categories and n_prototypes, and behaves similarly to \n",
    "# the CountVectorizer in terms of the transformation's shape\n",
    "mod = dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=200)\n",
    "mod.fit_transform(data[['employee_position_title']]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5361a31-f3fa-481e-9423-97068b9dce71",
   "metadata": {},
   "source": [
    "## Vincent's Pipeline code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfdeb806-77f7-48da-a43e-ff7f2a8a1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline imports all required packages, sets up a method dictionary to be used in looping through various\n",
    "# encoders, and then grid searches logging the 'neg_mean_absolute_error' for each model\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklego.preprocessing import ColumnSelector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "method = {\n",
    "    'sim_enc100': dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=100),\n",
    "    'sim_enc300': dirty_cat.SimilarityEncoder(categories='most_frequent', n_prototypes=300),\n",
    "    'sim_enc_all': dirty_cat.SimilarityEncoder(),\n",
    "    'one-hot': OneHotEncoder(handle_unknown='ignore')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for k, encoder in method.items():\n",
    "    pipe = Pipeline([\n",
    "        ('split', FeatureUnion([\n",
    "            ('cat', Pipeline([\n",
    "                ('grab', ColumnSelector(['employee_position_title'])),\n",
    "                ('handle', encoder)\n",
    "            ])),\n",
    "            ('one-hot', Pipeline([\n",
    "                ('grab', ColumnSelector('assignment_category')),\n",
    "                ('handle', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ])),\n",
    "            ('floats', Pipeline([\n",
    "                ('grab', ColumnSelector('year_first_hired')),\n",
    "                ('scale', StandardScaler())\n",
    "            ])),\n",
    "        ])),\n",
    "        ('mod', Ridge())\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipe, cv=10, param_grid={}, scoring=['r2', 'neg_mean_absolute_error'], refit='r2', n_jobs=-1)\n",
    "    res_df = pd.DataFrame(grid.fit(X, y).cv_results_)\n",
    "    res_df['key'] = k\n",
    "    results.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b4216e-7d1e-46ac-bdf7-c80484fdac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "cv_ngram\n"
     ]
    }
   ],
   "source": [
    "# This pipeline imports all required packages, sets up a method dictionary to be used in looping through various\n",
    "# count vectorizers, and then grid searches logging the 'neg_mean_absolute_error' for each model\n",
    "# The count vectorizers are not included in the pipeline above because they accept a df column as input, while \n",
    "# the encoders accept a dataframe with one colum\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "method = {\n",
    "    'cv': CountVectorizer(),\n",
    "    'cv_ngram': CountVectorizer(analyzer='char', ngram_range=(2, 4)),\n",
    "}\n",
    "\n",
    "for k, encoder in method.items():\n",
    "  pipe = Pipeline([\n",
    "    ('split', FeatureUnion([\n",
    "      ('cat', Pipeline([\n",
    "        ('listify', FunctionTransformer(lambda d: [t for t in d['employee_position_title']])),\n",
    "        ('handle', encoder)\n",
    "      ])),\n",
    "      ('one-hot', Pipeline([\n",
    "        ('grab', ColumnSelector('assignment_category')),\n",
    "        ('handle', OneHotEncoder(handle_unknown='ignore'))\n",
    "      ])),\n",
    "\n",
    "      ('floats', Pipeline([\n",
    "        ('grab', ColumnSelector('year_first_hired')),\n",
    "        ('scale', StandardScaler())\n",
    "      ])),\n",
    "    ])),\n",
    "    ('mod', Ridge())\n",
    "  ])\n",
    "  grid = GridSearchCV(pipe, cv=10, param_grid={}, scoring=['r2', 'neg_mean_absolute_error'], refit='r2', n_jobs=-1)\n",
    "  print(k)\n",
    "  res_df = pd.DataFrame(grid.fit(X, y).cv_results_)\n",
    "  res_df['key'] = k\n",
    "  results.append(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26645b21-d284-4f84-b03d-78bfedf3f68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean_test_neg_mean_absolute_error</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6279.078331</td>\n",
       "      <td>0.902077</td>\n",
       "      <td>cv_ngram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-6319.690323</td>\n",
       "      <td>0.901846</td>\n",
       "      <td>sim_enc_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-6829.004776</td>\n",
       "      <td>0.885858</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-6577.095979</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>sim_enc300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-6393.727621</td>\n",
       "      <td>0.861620</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-7779.914298</td>\n",
       "      <td>0.789175</td>\n",
       "      <td>sim_enc100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  mean_test_neg_mean_absolute_error  mean_test_r2          key\n",
       "0      0                       -6279.078331      0.902077     cv_ngram\n",
       "1      0                       -6319.690323      0.901846  sim_enc_all\n",
       "2      0                       -6829.004776      0.885858           cv\n",
       "3      0                       -6577.095979      0.875012   sim_enc300\n",
       "4      0                       -6393.727621      0.861620      one-hot\n",
       "5      0                       -7779.914298      0.789175   sim_enc100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lines below concatenate the results from each pipeline\n",
    "plt_df = pd.concat(results)[['mean_test_neg_mean_absolute_error', 'mean_test_r2', 'key']]\n",
    "plt_df.sort_values('mean_test_r2', ascending=False).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
